{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controlling LLM output with Logit Bias\n",
    "\n",
    "\n",
    "<a href=\"https://help.openai.com/en/articles/5247780-using-logit-bias-to-define-token-probability\">OpenAI Logit Bias Article</a>\n",
    "\n",
    "Here you'll go through some basic logit bias exercizes for understanding logit bias with the OpenAI API."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the LogitBias class defined in logit_bias.py to create the bias map.\n",
    "\n",
    "\n",
    "<img src=\"/Users/samuel.shapley/projects/AI/SemanticGPT/images/definition.png\" width=\"750\" height=\"300\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import textwrap\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "# Get the parent directory of the current directory\n",
    "parent_dir = os.path.dirname(cwd)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Now Python knows where to find logit_bias package\n",
    "from logit_bias import LogitBias\n",
    "\n",
    "# Define the API key and model\n",
    "api_key = 'API_KEY'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code shows the most basic implementation of logit bias. By supressing a given phrase (BIAS = -100), we can explore how LLM's alter their responses once a certain section of the probability distribution has been restricted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LogitBias class\n",
    "logit_bias_generator = LogitBias(\n",
    "    api_key=api_key, \n",
    "    model='gpt-4', \n",
    "    suppressed_phrases=['2','two'],\n",
    "    bias=-100,\n",
    "    request_timeout=100\n",
    ")\n",
    "\n",
    "# Generate a single response using the generate_response method\n",
    "logit_bias_generator.generate_response(\n",
    "    prompt = \"How many hands do humans have?\",\n",
    "    system_message=\"PAY ATTENTION TO THE QUESTION\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this function to do quick experiments with language models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment 1: Arithmetic\n",
    "\n",
    "What if we stop the language model from getting the right answer in basic addition questions? \n",
    "How close does it get?\n",
    "\n",
    "Here is a high level overview of the following code:\n",
    "\n",
    "1. Specify alphabet and special characters to supress\n",
    "2. Generate a list of all possible sums of distinct integer pairs from 1 - 1000.\n",
    "3. Choose a 10K random sample (this was for large statistics in the demo and takes ~1.5hr for ~£5)\n",
    "4. Prompt the model with \"a + b = \" and supress the answer and numbers to sum.\n",
    "5. Record the response, extracting the numbers and handling errors if any occur.\n",
    "\n",
    "The result of this experiment is found in <code>arithmetic_pairs.json</code>, which is explored in the subsequent cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get number pairs from uniform distribution.\n",
    "\n",
    "num_samples = 2000\n",
    "sums = {}\n",
    "\n",
    "while len(sums) < num_samples:\n",
    "    a = random.randint(1, 100000)\n",
    "    b = random.randint(1, 100000)\n",
    "    sum_ab = a + b\n",
    "    if sum_ab not in sums:\n",
    "        sums[sum_ab] = [a, b, sum_ab]\n",
    "\n",
    "sums = list(sums.values())\n",
    "\n",
    "sums = random.sample(sums,num_samples)\n",
    "\n",
    "# get the sums only from the 'sums' list\n",
    "sum_values = [sum[2] for sum in sums] \n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(sum_values, bins=50, edgecolor='black')\n",
    "plt.title('Distribution of Sums')\n",
    "plt.xlabel('Sum')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = [\n",
    "    'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W',\n",
    "    'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't',\n",
    "    'u', 'v', 'w', 'x', 'y', 'z'\n",
    "]\n",
    "\n",
    "special_characters = [\n",
    "    '{', '}', ',', '?', '*', '=', '.', '(', ')', '[', ']', '!', '+', '/', '%', '^', '_', '\"', \"'\"\n",
    "]\n",
    "\n",
    "\n",
    "system_message = \"\"\"You add two numbers together. Under no circumstances should you use any other characters than 0-9.\n",
    "Respond with a single number.\n",
    "\"\"\"\n",
    "\n",
    "results = []\n",
    "for i, (a, b, sum) in enumerate(tqdm(sums)):\n",
    "    prompt = f\"{a} + {b} =\"\n",
    "    try:\n",
    "        logit_bias_generator = LogitBias(\n",
    "            api_key=api_key, \n",
    "            model='gpt-4', \n",
    "            suppressed_phrases=[f\"{sum}\",f\"{a}\",f\"{b}\",f\"{a}{b}\"]+alphabet+special_characters,\n",
    "            bias=-100,\n",
    "            request_timeout=10)\n",
    "        response = logit_bias_generator.generate_response(\n",
    "            prompt=prompt,\n",
    "            temperature=0)\n",
    "    except Exception as e:\n",
    "        results.append({\n",
    "            'first_number': a,\n",
    "            'second_number': b,\n",
    "            'correct_sum': sum,\n",
    "            'model_response': None,\n",
    "            'extracted_numbers': None,\n",
    "            'model_breakdown': True,\n",
    "            'error': str(e)\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    numbers = \"\".join(c for c in response if c.isdigit())\n",
    "\n",
    "    # print(str(sum), numbers)\n",
    "\n",
    "    results.append({\n",
    "        'first_number': a,\n",
    "        'second_number': b,\n",
    "        'correct_sum': sum,\n",
    "        'model_response': response,\n",
    "        'extracted_numbers': numbers,\n",
    "        'model_breakdown': False,\n",
    "        'error': None\n",
    "    })\n",
    "\n",
    "    if i % 5 == 0:\n",
    "        with open('arithmetic_pairs_100K_test.json', 'w') as json_file:\n",
    "            json.dump(results, json_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've got our arithmetic_pairs JSON, load it into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data from the JSON file\n",
    "with open('arithmetic_pairs_100k.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# create a DataFrame from the data\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_int(x):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# make a copy of the original dataframe\n",
    "df_clean = df.copy()\n",
    "\n",
    "# create a mask for entries without a model breakdown\n",
    "mask = ~df_clean['model_breakdown']\n",
    "\n",
    "# convert the extracted numbers to integers\n",
    "df_clean.loc[mask, 'extracted_numbers'] = df_clean.loc[mask, 'extracted_numbers'].apply(convert_to_int)\n",
    "\n",
    "\n",
    "\n",
    "# compute the difference\n",
    "df_clean.loc[mask, 'difference'] = abs(df_clean.loc[mask, 'correct_sum'] - df_clean.loc[mask, 'extracted_numbers'])\n",
    "\n",
    "df_clean.loc[mask, 'difference_proportion'] = df_clean.loc[mask, 'difference'] / df_clean.loc[mask, 'correct_sum']\n",
    "\n",
    "# plot the difference against the correct sum\n",
    "plt.figure(figsize=(9, 4))\n",
    "plt.scatter(df_clean['correct_sum'], df_clean['difference'],marker='.')\n",
    "plt.xlabel('Correct Sum')\n",
    "plt.ylabel('Difference')\n",
    "plt.title('Error Size against True Answer Size')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "### Strangely, the differences follow three distinct lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def average_difference():\n",
    "    # Generate 1000K random numbers up to 200K\n",
    "    orig_nums = [random.randint(1, 200000) for _ in range(10000000)]\n",
    "    \n",
    "    # Create a list of numbers by duplicating first digit\n",
    "    trans_nums = [int(str(num)[0] + str(num)) for num in orig_nums]\n",
    "    \n",
    "    # Calculate and return the average difference\n",
    "    diff = [(trans - orig)/orig for trans, orig in zip(trans_nums, orig_nums)]\n",
    "    return sum(diff) / len(diff)\n",
    "\n",
    "print(average_difference())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all the ones where difference/sum is greater than 1\n",
    "df_clean[df_clean['difference_proportion'] > 1]\n",
    "\n",
    "### The error size grows almost predictably, as the errors made by gpt-4 are predictable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all the ones where difference is the same as the correct sum\n",
    "df_clean[df_clean['difference'] == df_clean['correct_sum']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment 2: Language\n",
    "\n",
    "What does an LLM say if it can't? \n",
    "\n",
    "Ask GPT to repeat a word, and it will do so without hesitatation. However, if the word to repeat is suppressed,\n",
    "the model is forced to choose a different answer. \n",
    "\n",
    "This is set up in <code>suppression_loop</code>. Choose a new supression word and run the cell to see how GPT views words as similar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suppression_loop(API_KEY: str, MODEL: str, suppression_word: str, temperature: float=0, request_timeout: int=10) -> None:\n",
    "    BIAS = -100\n",
    "\n",
    "    suppressed_phrases = [suppression_word]\n",
    "    logit_bias_generator = LogitBias(API_KEY, MODEL, suppressed_phrases, BIAS, request_timeout=request_timeout)\n",
    "\n",
    "    system_message = \"You can only produce real single words. Repeat the word you see in the prompt.\"\n",
    "    \n",
    "    while True:\n",
    "        PROMPT = f\"{suppression_word}\"\n",
    "        response = logit_bias_generator.generate_response(PROMPT, temperature, system_message)\n",
    "        print(response)\n",
    "        suppressed_phrases.append(response)\n",
    "        logit_bias_generator = LogitBias(API_KEY, MODEL, suppressed_phrases, BIAS, request_timeout=request_timeout)\n",
    "\n",
    "MODEL = \"gpt-4\"\n",
    "suppression_word = \"world\"\n",
    "suppression_loop(api_key, MODEL, suppression_word, request_timeout=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your own word network!\n",
    "\n",
    "Type in a word and watch the network grow as GPT explores similar possibilities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bd385fe162c5ca0c84973b7dd5c518456272446b2b64e67c2a69f949ca7a1754"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
